{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom spacy.tokenizer import Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport spacy\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nfrom nltk.corpus import stopwords \nimport random\nfrom tqdm import tqdm\nfrom PIL import Image\nimport math\nimport json\nfrom collections import defaultdict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T20:19:19.646369Z","iopub.execute_input":"2024-02-24T20:19:19.646766Z","iopub.status.idle":"2024-02-24T20:19:19.654890Z","shell.execute_reply.started":"2024-02-24T20:19:19.646733Z","shell.execute_reply":"2024-02-24T20:19:19.654038Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Tokenizer using spacy\nnlp = spacy.load(\"en_core_web_sm\")\ntokenizer = Tokenizer(nlp.vocab)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:34.675058Z","iopub.execute_input":"2024-02-24T17:06:34.675618Z","iopub.status.idle":"2024-02-24T17:06:35.832762Z","shell.execute_reply.started":"2024-02-24T17:06:34.675592Z","shell.execute_reply":"2024-02-24T17:06:35.831755Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Check accuracy function\ndef check_accuracy(output,labels):\n    _ , predpos = output.max(1)\n    num_samples=len(labels)\n    num_correct=(predpos==labels).sum()\n    return (num_correct/num_samples)*100\n\n# Save checkpoint\ndef save_checkpoint(state,filename='weights.pth.tar'):\n    print('Saving weights-->')\n    torch.save(state,filename)\n\n# Load checkpoint\ndef load_checkpoint(filename,model,optim):\n    print('Loading weights-->')\n    checkpoint = torch.load(filename)\n    model.load_state_dict(checkpoint['state_dict'])\n    optim.load_state_dict(checkpoint['optimizer'])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:29:01.356265Z","iopub.execute_input":"2024-02-24T20:29:01.356656Z","iopub.status.idle":"2024-02-24T20:29:01.363586Z","shell.execute_reply.started":"2024-02-24T20:29:01.356626Z","shell.execute_reply":"2024-02-24T20:29:01.362613Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(BASE_PATH,json_file,image_folder):\n    path = os.path.join(BASE_PATH,\"annotations/\"+json_file)\n    with open(path) as f:\n        data = json.load(f)\n        data = data['annotations']\n\n    img_cap_pairs = []\n\n    for sample in data:\n        img_name = '%012d.jpg' % sample['image_id']\n        img_cap_pairs.append([img_name, sample['caption']])\n\n    captions = pd.DataFrame(img_cap_pairs, columns=['image', 'caption'])\n    captions['image'] = captions['image'].apply(\n        lambda x: f'{BASE_PATH}/{image_folder}/{x}'\n    )\n    captions = captions.reset_index(drop=True)\n    return captions","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:35.844093Z","iopub.execute_input":"2024-02-24T17:06:35.844464Z","iopub.status.idle":"2024-02-24T17:06:35.851827Z","shell.execute_reply.started":"2024-02-24T17:06:35.844432Z","shell.execute_reply":"2024-02-24T17:06:35.850957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df = create_dataframe(\"/kaggle/input/coco-2017-dataset/coco2017\",\"captions_train2017.json\",\"train2017\")\nval_df = create_dataframe(\"/kaggle/input/coco-2017-dataset/coco2017\",\"captions_val2017.json\",\"val2017\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:35.852831Z","iopub.execute_input":"2024-02-24T17:06:35.853123Z","iopub.status.idle":"2024-02-24T17:06:40.135364Z","shell.execute_reply.started":"2024-02-24T17:06:35.853100Z","shell.execute_reply":"2024-02-24T17:06:40.134354Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.sample(40000)\ntrain_df = train_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.136522Z","iopub.execute_input":"2024-02-24T17:06:40.136876Z","iopub.status.idle":"2024-02-24T17:06:40.202624Z","shell.execute_reply.started":"2024-02-24T17:06:40.136846Z","shell.execute_reply":"2024-02-24T17:06:40.201917Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"val_df  =val_df.sample(10000)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.203571Z","iopub.execute_input":"2024-02-24T17:06:40.203825Z","iopub.status.idle":"2024-02-24T17:06:40.211873Z","shell.execute_reply.started":"2024-02-24T17:06:40.203804Z","shell.execute_reply":"2024-02-24T17:06:40.211060Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.212938Z","iopub.execute_input":"2024-02-24T17:06:40.213329Z","iopub.status.idle":"2024-02-24T17:06:40.218669Z","shell.execute_reply.started":"2024-02-24T17:06:40.213305Z","shell.execute_reply":"2024-02-24T17:06:40.217738Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(40000, 2) (10000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.219940Z","iopub.execute_input":"2024-02-24T17:06:40.220529Z","iopub.status.idle":"2024-02-24T17:06:40.238276Z","shell.execute_reply.started":"2024-02-24T17:06:40.220506Z","shell.execute_reply":"2024-02-24T17:06:40.237212Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                               image  \\\n0  /kaggle/input/coco-2017-dataset/coco2017/train...   \n1  /kaggle/input/coco-2017-dataset/coco2017/train...   \n2  /kaggle/input/coco-2017-dataset/coco2017/train...   \n3  /kaggle/input/coco-2017-dataset/coco2017/train...   \n4  /kaggle/input/coco-2017-dataset/coco2017/train...   \n\n                                             caption  \n0  A close up of a person holding a battered onio...  \n1  A cookie-ice cream sandwich is served with a s...  \n2            A bare bathroom with a sink and toilet.  \n3  A man in sunglasses and a blue shirt holds a m...  \n4  Two double decker buses pull away from a build...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>A close up of a person holding a battered onio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>A cookie-ice cream sandwich is served with a s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>A bare bathroom with a sink and toilet.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>A man in sunglasses and a blue shirt holds a m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>Two double decker buses pull away from a build...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n\n                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n\n                           \"you're\": \"you are\", \"you've\": \"you have\"}\n\n\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.242894Z","iopub.execute_input":"2024-02-24T17:06:40.243140Z","iopub.status.idle":"2024-02-24T17:06:40.259065Z","shell.execute_reply.started":"2024-02-24T17:06:40.243118Z","shell.execute_reply":"2024-02-24T17:06:40.258208Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def text_cleaner(text):\n    newString = text.lower()\n    newString = newString.replace('\"', \"'\")\n    newString = re.sub(r'\\([^)]*\\)', '', newString)\n    newString = re.sub('\"','', newString)\n    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n    newString = re.sub(r\"'s\\b\",\"\",newString)\n    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n    tokens = [w for w in newString.split()]\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.260110Z","iopub.execute_input":"2024-02-24T17:06:40.260401Z","iopub.status.idle":"2024-02-24T17:06:40.269548Z","shell.execute_reply.started":"2024-02-24T17:06:40.260379Z","shell.execute_reply":"2024-02-24T17:06:40.268630Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Clean text in train and val dataframe\ntrain_df['caption'] = train_df['caption'].apply(lambda x: [token.text.lower() for token in tokenizer(text_cleaner(x))])\nval_df['caption'] = val_df['caption'].apply(lambda x: [token.text.lower() for token in tokenizer(text_cleaner(x))])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:40.270513Z","iopub.execute_input":"2024-02-24T17:06:40.270767Z","iopub.status.idle":"2024-02-24T17:06:43.046958Z","shell.execute_reply.started":"2024-02-24T17:06:40.270740Z","shell.execute_reply":"2024-02-24T17:06:43.045987Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Add START AND END tokens to summary\ntrain_df['caption'] = train_df['caption'].apply(lambda x : ['_START_']+ x + ['_END_'])\nval_df['caption'] = val_df['caption'].apply(lambda x : ['_START_']+ x + ['_END_'])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.048026Z","iopub.execute_input":"2024-02-24T17:06:43.048312Z","iopub.status.idle":"2024-02-24T17:06:43.108543Z","shell.execute_reply.started":"2024-02-24T17:06:43.048287Z","shell.execute_reply":"2024-02-24T17:06:43.107561Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.109809Z","iopub.execute_input":"2024-02-24T17:06:43.110401Z","iopub.status.idle":"2024-02-24T17:06:43.121430Z","shell.execute_reply.started":"2024-02-24T17:06:43.110368Z","shell.execute_reply":"2024-02-24T17:06:43.120488Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                               image  \\\n0  /kaggle/input/coco-2017-dataset/coco2017/train...   \n1  /kaggle/input/coco-2017-dataset/coco2017/train...   \n2  /kaggle/input/coco-2017-dataset/coco2017/train...   \n3  /kaggle/input/coco-2017-dataset/coco2017/train...   \n4  /kaggle/input/coco-2017-dataset/coco2017/train...   \n\n                                             caption  \n0  [_START_, a, close, up, of, a, person, holding...  \n1  [_START_, a, cookie, ice, cream, sandwich, is,...  \n2  [_START_, a, bare, bathroom, with, a, sink, an...  \n3  [_START_, a, man, in, sunglasses, and, a, blue...  \n4  [_START_, two, double, decker, buses, pull, aw...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>[_START_, a, close, up, of, a, person, holding...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>[_START_, a, cookie, ice, cream, sandwich, is,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>[_START_, a, bare, bathroom, with, a, sink, an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>[_START_, a, man, in, sunglasses, and, a, blue...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/coco-2017-dataset/coco2017/train...</td>\n      <td>[_START_, two, double, decker, buses, pull, aw...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_max_seqlen():\n    max_length = 0\n    for index, row in train_df.iterrows():\n        # Calculate the length of the current row\n        row_length = len(row['caption'])\n        # Update the maximum length if the current row length is greater\n        max_length = max(max_length, row_length)\n    for index, row in val_df.iterrows():\n        # Calculate the length of the current row\n        row_length = len(row['caption'])\n        # Update the maximum length if the current row length is greater\n        max_length = max(max_length, row_length)\n    print(\"Max length in dataset \",max_length)\n    return max_length","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.122730Z","iopub.execute_input":"2024-02-24T17:06:43.123016Z","iopub.status.idle":"2024-02-24T17:06:43.132462Z","shell.execute_reply.started":"2024-02-24T17:06:43.122993Z","shell.execute_reply":"2024-02-24T17:06:43.131526Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Build vocabularies - each word has an index, note : words sorted in ascending order\nall_tokens = train_df['caption'].tolist() + val_df['caption'].tolist()\ntarget_vocab = {actual_word: idx for idx, (word_num, actual_word) in enumerate(sorted(enumerate(set(token for tokens in all_tokens for token in tokens)), key=lambda x: x[1]))}","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.133591Z","iopub.execute_input":"2024-02-24T17:06:43.133934Z","iopub.status.idle":"2024-02-24T17:06:43.222586Z","shell.execute_reply.started":"2024-02-24T17:06:43.133904Z","shell.execute_reply":"2024-02-24T17:06:43.221821Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using\",device)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.223637Z","iopub.execute_input":"2024-02-24T17:06:43.223983Z","iopub.status.idle":"2024-02-24T17:06:43.229065Z","shell.execute_reply.started":"2024-02-24T17:06:43.223954Z","shell.execute_reply":"2024-02-24T17:06:43.227998Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Using cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"temp = list(sorted(target_vocab.items()))\nfor word, idx in temp[-5:]:\n    print(word,idx)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.230229Z","iopub.execute_input":"2024-02-24T17:06:43.230503Z","iopub.status.idle":"2024-02-24T17:06:43.244182Z","shell.execute_reply.started":"2024-02-24T17:06:43.230480Z","shell.execute_reply":"2024-02-24T17:06:43.243340Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"zone 9913\nzoo 9914\nzookeeper 9915\nzooming 9916\nzucchini 9917\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, target_vocab, image_transform=None):\n        self.dataframe = dataframe\n        self.target_vocab = target_vocab\n        self.image_transform = image_transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path=self.dataframe.loc[idx]['image']\n        image=Image.open(img_path)\n        caption = [self.target_vocab[word] for word in self.dataframe.loc[idx]['caption']]\n        if self.image_transform:\n            image = self.image_transform(image)\n        if image.shape[0] != 3:\n            return torch.randn((3,512,512)),torch.tensor(caption)\n        return image,torch.tensor(caption)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.245358Z","iopub.execute_input":"2024-02-24T17:06:43.245626Z","iopub.status.idle":"2024-02-24T17:06:43.255245Z","shell.execute_reply.started":"2024-02-24T17:06:43.245604Z","shell.execute_reply":"2024-02-24T17:06:43.254381Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"transform =transforms.Compose([\n    transforms.Resize((512,512)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.256358Z","iopub.execute_input":"2024-02-24T17:06:43.256624Z","iopub.status.idle":"2024-02-24T17:06:43.265324Z","shell.execute_reply.started":"2024-02-24T17:06:43.256601Z","shell.execute_reply":"2024-02-24T17:06:43.264518Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create custom datasets\ntrain_dataset = CustomDataset(train_df, target_vocab, transform)\nval_dataset = CustomDataset(val_df, target_vocab, transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.266367Z","iopub.execute_input":"2024-02-24T17:06:43.268576Z","iopub.status.idle":"2024-02-24T17:06:43.275024Z","shell.execute_reply.started":"2024-02-24T17:06:43.268545Z","shell.execute_reply":"2024-02-24T17:06:43.274036Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.276079Z","iopub.execute_input":"2024-02-24T17:06:43.276393Z","iopub.status.idle":"2024-02-24T17:06:43.285025Z","shell.execute_reply.started":"2024-02-24T17:06:43.276363Z","shell.execute_reply":"2024-02-24T17:06:43.284209Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"40000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define collate function for DataLoader\ndef collate_fn(batch):\n    images, captions = zip(*batch)\n    images = torch.stack(images,dim=0)\n    padded_captions = pad_sequence(captions, batch_first=True)\n    return images, padded_captions","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.286050Z","iopub.execute_input":"2024-02-24T17:06:43.286587Z","iopub.status.idle":"2024-02-24T17:06:43.294733Z","shell.execute_reply.started":"2024-02-24T17:06:43.286545Z","shell.execute_reply":"2024-02-24T17:06:43.293996Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Use pretrained resnet101 as feature extractor\nresnet_test = torchvision.models.resnet101(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:43.295762Z","iopub.execute_input":"2024-02-24T17:06:43.296016Z","iopub.status.idle":"2024-02-24T17:06:45.569154Z","shell.execute_reply.started":"2024-02-24T17:06:43.295995Z","shell.execute_reply":"2024-02-24T17:06:45.568290Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n100%|██████████| 171M/171M [00:01<00:00, 153MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"resnet_test.fc = nn.Linear(in_features = 2048, out_features = 512)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.570837Z","iopub.execute_input":"2024-02-24T17:06:45.571228Z","iopub.status.idle":"2024-02-24T17:06:45.585544Z","shell.execute_reply.started":"2024-02-24T17:06:45.571193Z","shell.execute_reply":"2024-02-24T17:06:45.584792Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(resnet_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.586512Z","iopub.execute_input":"2024-02-24T17:06:45.586795Z","iopub.status.idle":"2024-02-24T17:06:45.594645Z","shell.execute_reply.started":"2024-02-24T17:06:45.586772Z","shell.execute_reply":"2024-02-24T17:06:45.593755Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=512, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use pretrained resnet101 as feature extractor\ndef get_resnet_encoder(out_features,pretrained=True):\n    resnet_encoder = torchvision.models.resnet101(pretrained=pretrained)\n    # Modify this model to encode feature to embedding_dim = 512, so that the \n    # image feature encoding can be used for Cross Attention in Decoder only Transformer\n    resnet_encoder.fc = nn.Linear(in_features = 2048, out_features = out_features)\n    return resnet_encoder","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.595791Z","iopub.execute_input":"2024-02-24T17:06:45.596045Z","iopub.status.idle":"2024-02-24T17:06:45.603023Z","shell.execute_reply.started":"2024-02-24T17:06:45.596023Z","shell.execute_reply":"2024-02-24T17:06:45.602205Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, embedding_dim, num_heads):\n        super(MultiHeadAttention,self).__init__()\n        assert embedding_dim % num_heads == 0, \"embedding_dim must be divisible by num_heads\"\n\n        self.embedding_dim = embedding_dim\n        self.num_heads = num_heads\n        self.dim_perhead = embedding_dim // num_heads\n\n        self.W_q = nn.Linear(embedding_dim, embedding_dim)\n        self.W_k = nn.Linear(embedding_dim, embedding_dim)\n        self.W_v = nn.Linear(embedding_dim, embedding_dim)\n        self.W_o = nn.Linear(embedding_dim, embedding_dim)\n\n    def scaled_dot_product_attention(self,Q,K,V,mask=None):\n        # Q,K,V Shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        \n        K = K.transpose(-2,-1) # K = K.permute(0,1,3,2) also works\n        # K Shape(after permute) : [Batch_Size X Num_Heads X Dim Per Head X Seq_len]\n        attn_scores = torch.matmul(Q,K) / math.sqrt(self.dim_perhead)\n        # attn_scores Shape : [Batch_Size X Num_Heads X Seq_len X Seq_len]\n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        # attn_probs Shape : [Batch_Size X Num_Heads X Seq_len X Seq_len]\n        output = torch.matmul(attn_probs, V)\n        # output Shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        return output\n\n    def split_heads(self, x):\n        # X shape : [Batch_Size X Seq_len X Embedding Dim]\n        batch_size, seq_length, d_model = x.size()\n        x = x.view(batch_size, seq_length,self.num_heads,self.dim_perhead)\n        # X shape : [Batch_Size X Seq_len X Num_Heads X Dim Per Head]\n        x = x.transpose(1,2)\n        # X shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        return x\n\n    def combine_heads(self, x):\n        # x Shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        batch_size, _, seq_length, dim_perhead = x.size()\n        x = x.transpose(1,2).contiguous()\n        # x Shape : [Batch_Size X Seq_len X Num_Heads X Dim Per Head]\n        x = x.view(batch_size, seq_length,self.embedding_dim)\n        # x Shape : [Batch_Size X Seq_len X Embedding Dim]\n        return x\n\n    def forward(self, Q, K, V, mask=None):\n        # Q,K,V Shape : [Batch_Size X Seq_len X Embedding Dim]\n        Q = self.split_heads(self.W_q(Q)) \n        K = self.split_heads(self.W_k(K)) \n        V = self.split_heads(self.W_v(V)) \n        # Q,K,V Shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n        # attn_output Shape : [Batch_Size X Num_Heads X Seq_len X Dim Per Head]\n        output = self.W_o(self.combine_heads(attn_output))\n        # output Shape :  # x Shape : [Batch_Size X Seq_len X Embedding Dim]\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.609392Z","iopub.execute_input":"2024-02-24T17:06:45.609648Z","iopub.status.idle":"2024-02-24T17:06:45.624342Z","shell.execute_reply.started":"2024-02-24T17:06:45.609616Z","shell.execute_reply":"2024-02-24T17:06:45.623372Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class PositionWiseFeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super(PositionWiseFeedForward, self).__init__()\n        self.fc1 = nn.Linear(d_model, d_ff)\n        self.fc2 = nn.Linear(d_ff, d_model)\n\n    def forward(self, x):\n        # shape does not change here\n        return self.fc2(F.relu(self.fc1(x)))\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_seq_length):\n        super(PositionalEncoding, self).__init__()\n\n        pe = torch.zeros(max_seq_length, d_model)\n        position = torch.arange(0, max_seq_length,dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model,2).float() * -(math.log(10000.0) / d_model))\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        self.register_buffer('pe',pe.unsqueeze(0))\n\n    def forward(self, x):\n        # shape does not change here, adding positional encoding information\n        return x + self.pe[:, :x.size(1)]","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.625536Z","iopub.execute_input":"2024-02-24T17:06:45.625813Z","iopub.status.idle":"2024-02-24T17:06:45.638147Z","shell.execute_reply.started":"2024-02-24T17:06:45.625789Z","shell.execute_reply":"2024-02-24T17:06:45.637416Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout):\n        super(DecoderLayer, self).__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output = self.self_attn(x, x, x,tgt_mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        attn_output = self.cross_attn(x,enc_output,enc_output,src_mask)\n        x = self.norm2(x + self.dropout(attn_output))\n        ff_output = self.feed_forward(x)\n        x = self.norm3(x + self.dropout(ff_output))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.639087Z","iopub.execute_input":"2024-02-24T17:06:45.639370Z","iopub.status.idle":"2024-02-24T17:06:45.652426Z","shell.execute_reply.started":"2024-02-24T17:06:45.639348Z","shell.execute_reply":"2024-02-24T17:06:45.651592Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class Encoder_Decoder(nn.Module):\n    def __init__(self, resnet_encoder, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout, device):\n        super(Encoder_Decoder, self).__init__()\n        self.encoder = resnet_encoder\n        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n\n        self.fc = nn.Linear(d_model, tgt_vocab_size)\n        self.dropout = nn.Dropout(dropout)\n        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n        self.device = device\n\n    def generate_mask(self, src, tgt):\n        src_mask = None\n        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n        seq_length = tgt.size(1)\n        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n        tgt_mask = tgt_mask & nopeak_mask\n        return src_mask, tgt_mask\n\n    def forward(self, img, caption):\n        # img shape : [batch_size X 3 X 512 X 512]  ,  caption shape : [batch_size X seq_len]\n        src_mask, caption_mask = self.generate_mask(img, caption)\n        caption_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(caption)))\n        # caption_embedded : [batch_size X seq_len X embedding_dim]\n        \n        enc_output = self.encoder(img) \n        # enc_output shape : [batch_size X 512]\n        enc_output = enc_output.unsqueeze(1)\n        # enc_output shape : [batch_size X 1 X 512]\n        dec_output = caption_embedded\n        for dec_layer in self.decoder_layers:\n            dec_output = dec_layer(dec_output, enc_output, src_mask, caption_mask)\n        output = self.fc(dec_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:43:14.577120Z","iopub.execute_input":"2024-02-24T20:43:14.577536Z","iopub.status.idle":"2024-02-24T20:43:14.590285Z","shell.execute_reply.started":"2024-02-24T20:43:14.577490Z","shell.execute_reply":"2024-02-24T20:43:14.589193Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"tgt_vocab_size = len(target_vocab)\nd_model = 512\nnum_heads = 8\nnum_layers = 6\nd_ff = 2048\nmax_seq_length = get_max_seqlen()\ndropout = 0.1\nnum_workers = 2\nnum_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:45.665224Z","iopub.execute_input":"2024-02-24T17:06:45.665488Z","iopub.status.idle":"2024-02-24T17:06:48.320461Z","shell.execute_reply.started":"2024-02-24T17:06:45.665466Z","shell.execute_reply":"2024-02-24T17:06:48.319521Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Max length in dataset  51\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet_encoder = get_resnet_encoder(d_model,pretrained=True)\nmodel = Encoder_Decoder(resnet_encoder, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout,device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:34:38.164685Z","iopub.execute_input":"2024-02-24T20:34:38.165047Z","iopub.status.idle":"2024-02-24T20:34:39.708009Z","shell.execute_reply.started":"2024-02-24T20:34:38.165019Z","shell.execute_reply":"2024-02-24T20:34:39.706892Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Encoder_Decoder(\n  (encoder): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (8): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (9): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (10): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (11): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (12): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (13): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (14): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (15): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (16): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (17): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (18): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (19): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (20): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (21): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (22): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=512, bias=True)\n  )\n  (decoder_embedding): Embedding(9918, 512)\n  (decoder_layers): ModuleList(\n    (0-5): 6 x DecoderLayer(\n      (self_attn): MultiHeadAttention(\n        (W_q): Linear(in_features=512, out_features=512, bias=True)\n        (W_k): Linear(in_features=512, out_features=512, bias=True)\n        (W_v): Linear(in_features=512, out_features=512, bias=True)\n        (W_o): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (cross_attn): MultiHeadAttention(\n        (W_q): Linear(in_features=512, out_features=512, bias=True)\n        (W_k): Linear(in_features=512, out_features=512, bias=True)\n        (W_v): Linear(in_features=512, out_features=512, bias=True)\n        (W_o): Linear(in_features=512, out_features=512, bias=True)\n      )\n      (feed_forward): PositionWiseFeedForward(\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n      )\n      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (fc): Linear(in_features=512, out_features=9918, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (positional_encoding): PositionalEncoding()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(trainable_params)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:49.596497Z","iopub.execute_input":"2024-02-24T17:06:49.597048Z","iopub.status.idle":"2024-02-24T17:06:49.604715Z","shell.execute_reply.started":"2024-02-24T17:06:49.597013Z","shell.execute_reply":"2024-02-24T17:06:49.603823Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"78939390\n","output_type":"stream"}]},{"cell_type":"code","source":"# Specify optimizer and loss function\ncriterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:49.605935Z","iopub.execute_input":"2024-02-24T17:06:49.606474Z","iopub.status.idle":"2024-02-24T17:06:49.620085Z","shell.execute_reply.started":"2024-02-24T17:06:49.606440Z","shell.execute_reply":"2024-02-24T17:06:49.619204Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:49.621124Z","iopub.execute_input":"2024-02-24T17:06:49.621425Z","iopub.status.idle":"2024-02-24T17:06:49.629555Z","shell.execute_reply.started":"2024-02-24T17:06:49.621402Z","shell.execute_reply":"2024-02-24T17:06:49.628791Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"source_dummy,target_dummy = next(iter(train_loader))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:49.630573Z","iopub.execute_input":"2024-02-24T17:06:49.630820Z","iopub.status.idle":"2024-02-24T17:06:50.120628Z","shell.execute_reply.started":"2024-02-24T17:06:49.630799Z","shell.execute_reply":"2024-02-24T17:06:50.119471Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(source_dummy.shape,target_dummy.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:50.122106Z","iopub.execute_input":"2024-02-24T17:06:50.122457Z","iopub.status.idle":"2024-02-24T17:06:50.127877Z","shell.execute_reply.started":"2024-02-24T17:06:50.122428Z","shell.execute_reply":"2024-02-24T17:06:50.126980Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"torch.Size([8, 3, 512, 512]) torch.Size([8, 15])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(target_dummy[3].dtype)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:50.129002Z","iopub.execute_input":"2024-02-24T17:06:50.129869Z","iopub.status.idle":"2024-02-24T17:06:50.139661Z","shell.execute_reply.started":"2024-02-24T17:06:50.129843Z","shell.execute_reply":"2024-02-24T17:06:50.138801Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"torch.int64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(torch.min(target_dummy),torch.max(target_dummy))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:50.140625Z","iopub.execute_input":"2024-02-24T17:06:50.140900Z","iopub.status.idle":"2024-02-24T17:06:50.154186Z","shell.execute_reply.started":"2024-02-24T17:06:50.140877Z","shell.execute_reply":"2024-02-24T17:06:50.153357Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"tensor(0) tensor(9783)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)\nsource_dummy = source_dummy.to(device)\ntarget_dummy = target_dummy.to(device)\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:50.155266Z","iopub.execute_input":"2024-02-24T17:06:50.156091Z","iopub.status.idle":"2024-02-24T17:06:50.412542Z","shell.execute_reply.started":"2024-02-24T17:06:50.156068Z","shell.execute_reply":"2024-02-24T17:06:50.411593Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model(source_dummy,target_dummy)\nprint(y_pred.shape,target_dummy.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:50.413579Z","iopub.execute_input":"2024-02-24T17:06:50.413873Z","iopub.status.idle":"2024-02-24T17:06:51.510970Z","shell.execute_reply.started":"2024-02-24T17:06:50.413847Z","shell.execute_reply":"2024-02-24T17:06:51.510063Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"torch.Size([8, 15, 9918]) torch.Size([8, 15])\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = y_pred.reshape(-1,len(target_vocab))\ntarget_dummy = target_dummy.reshape(-1)\nprint(y_pred.shape,target_dummy.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:51.512189Z","iopub.execute_input":"2024-02-24T17:06:51.512785Z","iopub.status.idle":"2024-02-24T17:06:51.518394Z","shell.execute_reply.started":"2024-02-24T17:06:51.512757Z","shell.execute_reply":"2024-02-24T17:06:51.517448Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"torch.Size([120, 9918]) torch.Size([120])\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_loop(model,dataloader,loss_fun,optimizer,device):\n    model.train()\n    model.to(device)\n    min_loss = None\n    for epoch in range(num_epochs):\n        losses = []\n        accuracies = []\n        loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=True)\n        for batch,(x,y) in loop:\n            # put on cuda\n            x = x.to(device)\n            y = y.to(device)\n    \n            # forward pass\n            y_pred = model(x,y)\n            \n            # calculate loss & accuracy\n            loss = loss_fun(y_pred.reshape(-1,len(target_vocab)),y.reshape(-1))\n            losses.append(loss.detach().item())\n            \n            accuracy = check_accuracy(y_pred.reshape(-1,len(target_vocab)),y.reshape(-1))\n            accuracies.append(accuracy.detach().item())\n            \n            # zero out prior gradients\n            optimizer.zero_grad()\n            \n            # backprop\n            loss.backward()\n            \n            # update weights\n            optimizer.step()\n            scheduler.step()\n            \n            # Update TQDM progress bar\n            loop.set_description(f\"Epoch [{epoch}/{num_epochs}] \")\n            loop.set_postfix(loss=loss.detach().item(), accuracy=accuracy.detach().item())\n\n        moving_loss = sum(losses) / len(losses)\n        moving_accuracy = sum(accuracies) / len(accuracies)\n        checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n        # Save check point\n        if min_loss == None:\n            min_loss = moving_loss\n            save_checkpoint(checkpoint)\n        elif moving_loss < min_loss:\n            min_loss = moving_loss\n            save_checkpoint(checkpoint)\n        print('Epoch {0} : Loss = {1} , Training Accuracy={2}'.format(epoch, moving_loss, moving_accuracy))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:51.519800Z","iopub.execute_input":"2024-02-24T17:06:51.520210Z","iopub.status.idle":"2024-02-24T17:06:51.532567Z","shell.execute_reply.started":"2024-02-24T17:06:51.520177Z","shell.execute_reply":"2024-02-24T17:06:51.531700Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_loop(model,train_loader,criterion,optimizer,device)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:06:51.533724Z","iopub.execute_input":"2024-02-24T17:06:51.534040Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch [0/5] : 100%|██████████| 5000/5000 [30:59<00:00,  2.69it/s, accuracy=64.7, loss=0.525]  \n","output_type":"stream"},{"name":"stdout","text":"Saving weights-->\nEpoch 0 : Loss = 0.7552891996013 , Training Accuracy=66.54491707992554\n","output_type":"stream"},{"name":"stderr","text":"Epoch [1/5] : 100%|██████████| 5000/5000 [30:55<00:00,  2.70it/s, accuracy=75.8, loss=0.118]   \n","output_type":"stream"},{"name":"stdout","text":"Saving weights-->\nEpoch 1 : Loss = 0.26876360664280946 , Training Accuracy=69.9179668586731\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/5] :  89%|████████▉ | 4460/5000 [27:47<03:22,  2.66it/s, accuracy=79.5, loss=0.181]   ","output_type":"stream"}]},{"cell_type":"code","source":"def test_loop(model,dataloader,loss_fun,device):\n    model.eval()\n    model.to(device)\n    losses = []\n    samples,correct = 0,0\n    loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=True)\n    with torch.no_grad():\n        for batch,(x,y) in loop:\n            # put on cuda\n            x = x.to(device)\n            y = y.to(device)\n\n            # forward pass\n            y_pred = model(x,y)\n            \n            # caclulate test loss\n            loss = loss_fun(y_pred.reshape(-1,len(target_vocab)),y.reshape(-1))\n            losses.append(loss.detach().item())\n\n            # accuracy over entire dataset\n            _,predpos=y_pred.reshape(-1,len(target_vocab)).max(1)\n            samples+=len(y.reshape(-1))\n            correct+=(predpos==y.reshape(-1)).sum().item()\n            \n            # Update TQDM progress bar\n            loop.set_postfix(loss=loss.item())\n\n    print(\"Final Test Accuracy = \",100 * (correct/samples))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:50:52.654666Z","iopub.execute_input":"2024-02-24T19:50:52.655531Z","iopub.status.idle":"2024-02-24T19:50:52.665510Z","shell.execute_reply.started":"2024-02-24T19:50:52.655484Z","shell.execute_reply":"2024-02-24T19:50:52.664476Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp.p\")\n    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n    os.remove('temp.p')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:15:24.862251Z","iopub.execute_input":"2024-02-24T20:15:24.862652Z","iopub.status.idle":"2024-02-24T20:15:24.868009Z","shell.execute_reply.started":"2024-02-24T20:15:24.862624Z","shell.execute_reply":"2024-02-24T20:15:24.866959Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"print_size_of_model(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:15:41.486550Z","iopub.execute_input":"2024-02-24T20:15:41.486953Z","iopub.status.idle":"2024-02-24T20:15:41.952972Z","shell.execute_reply.started":"2024-02-24T20:15:41.486923Z","shell.execute_reply":"2024-02-24T20:15:41.951986Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Size (MB): 316.497228\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\n\nstart = time.time()\ntest_loop(model,val_loader,criterion,device=torch.device(\"cuda\"))\nend = time.time()\nprint(\"Time Taken without Quantizing on CUDA\",end - start)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:34:58.008944Z","iopub.execute_input":"2024-02-24T20:34:58.009332Z","iopub.status.idle":"2024-02-24T20:37:33.831925Z","shell.execute_reply.started":"2024-02-24T20:34:58.009301Z","shell.execute_reply":"2024-02-24T20:37:33.830659Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"100%|██████████| 1250/1250 [02:35<00:00,  8.04it/s, loss=0.228]   \n","output_type":"stream"},{"name":"stdout","text":"Final Test Accuracy =  69.67381612839311\nTime Taken without Quantizing on CUDA 155.81649684906006\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Exploring Quantization on CPU, create model on CPU and load saved weights","metadata":{}},{"cell_type":"code","source":"# Create small val set for CPU\nval_df = val_df.sample(500)\nval_df = val_df.reset_index(drop=True)\nval_dataset = CustomDataset(val_df, target_vocab, transform)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:41:50.438186Z","iopub.execute_input":"2024-02-24T20:41:50.438605Z","iopub.status.idle":"2024-02-24T20:41:50.445682Z","shell.execute_reply.started":"2024-02-24T20:41:50.438574Z","shell.execute_reply":"2024-02-24T20:41:50.444631Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"resnet_encoder = get_resnet_encoder(d_model,pretrained=True)\nmodel = Encoder_Decoder(resnet_encoder, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout,torch.device(\"cpu\"))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:43:21.187711Z","iopub.execute_input":"2024-02-24T20:43:21.188084Z","iopub.status.idle":"2024-02-24T20:43:22.674870Z","shell.execute_reply.started":"2024-02-24T20:43:21.188055Z","shell.execute_reply":"2024-02-24T20:43:22.673840Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"load_checkpoint(\"/kaggle/working/weights.pth.tar\",model,optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:43:22.731508Z","iopub.execute_input":"2024-02-24T20:43:22.731825Z","iopub.status.idle":"2024-02-24T20:43:24.404739Z","shell.execute_reply.started":"2024-02-24T20:43:22.731800Z","shell.execute_reply":"2024-02-24T20:43:24.403676Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Loading weights-->\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check time for 500 samples on CPU without quantiztion\nstart = time.time()\ntest_loop(model,val_loader,criterion,device=torch.device(\"cpu\"))\nend = time.time()\nprint(\"Time Taken without Quantizing on CPU for 500 samples\",end - start)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:43:41.610692Z","iopub.execute_input":"2024-02-24T20:43:41.611567Z","iopub.status.idle":"2024-02-24T20:47:58.256223Z","shell.execute_reply.started":"2024-02-24T20:43:41.611523Z","shell.execute_reply":"2024-02-24T20:47:58.255029Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stderr","text":"100%|██████████| 63/63 [04:16<00:00,  4.06s/it, loss=0.0192]  ","output_type":"stream"},{"name":"stdout","text":"Final Test Accuracy =  69.92303872889771\nTime Taken without Quantizing on CPU for 500 samples 256.63870787620544\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dynamic Quantization or Post Training Quantization","metadata":{}},{"cell_type":"code","source":"# Exploring quantization\nfrom copy import deepcopy\nquantized_model = deepcopy(model).to(\"cpu\")\nquantized_model = torch.quantization.quantize_dynamic(quantized_model, {torch.nn.Linear, torch.nn.Conv2d, torch.nn.ReLU, torch.nn.BatchNorm2d}, dtype=torch.qint8)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:48:58.686493Z","iopub.execute_input":"2024-02-24T20:48:58.686865Z","iopub.status.idle":"2024-02-24T20:48:59.455736Z","shell.execute_reply.started":"2024-02-24T20:48:58.686837Z","shell.execute_reply":"2024-02-24T20:48:59.454959Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"print_size_of_model(quantized_model) # Reduced size of the model","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:49:02.464120Z","iopub.execute_input":"2024-02-24T20:49:02.465014Z","iopub.status.idle":"2024-02-24T20:49:03.004206Z","shell.execute_reply.started":"2024-02-24T20:49:02.464980Z","shell.execute_reply":"2024-02-24T20:49:03.003236Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Size (MB): 222.667296\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check time for 500 samples on CPU with quantiztion\nstart = time.time()\ntest_loop(quantized_model,val_loader,criterion,device=torch.device(\"cpu\"))\nend = time.time()\nprint(\"Time Taken with Quantizing \",end - start)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:49:07.565994Z","iopub.execute_input":"2024-02-24T20:49:07.566815Z","iopub.status.idle":"2024-02-24T20:53:08.855092Z","shell.execute_reply.started":"2024-02-24T20:49:07.566784Z","shell.execute_reply":"2024-02-24T20:53:08.853824Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stderr","text":"100%|██████████| 63/63 [04:01<00:00,  3.83s/it, loss=0.0189]  ","output_type":"stream"},{"name":"stdout","text":"Final Test Accuracy =  69.92303872889771\nTime Taken with Quantizing  241.28281617164612\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}